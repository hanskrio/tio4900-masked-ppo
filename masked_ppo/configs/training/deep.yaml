# configs/training/deep.yaml

# Inherit all settings from the default training configuration
defaults:
  - default
  - _self_  # Ensures this file's settings take precedence over defaults

# Override policy_kwargs specifically for a deeper architecture
policy_kwargs:
  # Example: 3 hidden layers, starting wider and narrowing.
  # Represents a 'deeper' network compared to the default [64, 64] or a wider [512, 256].
  net_arch: [256, 128, 128]

# Override specific hyperparameters for the 'deep' configuration
total_timesteps: 800_000   # Example: Increase total steps for deeper network

# --- PPO Specific Overrides ---
#n_steps: 4096
#batch_size: 512
#n_epochs: 30
#ent_coef: 0.1 
learning_rate: 0.0003 # Add linear schedule definition if desired, or keep default for now
# -----------------------------
